{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is a convolution? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from conv_net_utils import plot_with_annot, load_fashion\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_image = np.concatenate([np.arange(10), np.arange(10, 0, -1)]).reshape((4, 5))\n",
    "fig1 = plot_with_annot(small_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_image = np.pad(small_image, 1, 'constant')\n",
    "fig1 = plot_with_annot(small_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = np.array([[0, 1, 0], [1, 1, 1], [0, 1, 0]])\n",
    "\n",
    "fig2 = plot_with_annot(kernel) \n",
    "fig2.set_size_inches([1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = np.zeros(small_image.shape)\n",
    "\n",
    "result[1, 1] += np.sum(small_image[:3, :3] * kernel)\n",
    "fig3 = plot_with_annot(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result[1, 2] += np.sum(small_image[:3, 1:4] * kernel)\n",
    "fig3 = plot_with_annot(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result[1, 3] += np.sum(small_image[:3, 2:5] * kernel)\n",
    "fig3 = plot_with_annot(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = np.zeros(small_image.shape)\n",
    "\n",
    "for ii in range(small_image.shape[0]-2):\n",
    "    for jj in range(small_image.shape[1]-2):\n",
    "        result[ii+1, jj+1] = np.sum(small_image[ii:ii+kernel.shape[0], jj:jj+kernel.shape[1]] * kernel)\n",
    "\n",
    "_ = plot_with_annot(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = plt.imread('./bricks.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = np.mean(im[..., :3], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1)\n",
    "ax.matshow(im)\n",
    "ax.set_axis_off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = np.zeros(im.shape)\n",
    "\n",
    "for ii in range(1, im.shape[0]-2):\n",
    "    for jj in range(1, im.shape[1]-2):\n",
    "        conv[ii, jj] = np.sum(im[ii:ii+kernel.shape[0], jj:jj+kernel.shape[1]] * kernel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = np.array([[-0.5, -0.5, -0.5], [1, 1, 1], [-0.5, -0.5, -0.5]])\n",
    "fig2 = plot_with_annot(kernel, vmax=1)\n",
    "fig2.set_size_inches([1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = np.zeros(im.shape)\n",
    "\n",
    "for ii in range(1, im.shape[0]-2):\n",
    "    for jj in range(1, im.shape[1]-2):\n",
    "        conv[ii, jj] = np.sum(im[ii:ii+kernel.shape[0], jj:jj+kernel.shape[1]] * kernel)\n",
    "\n",
    "fig, ax = plt.subplots(1)\n",
    "ax.matshow(conv)\n",
    "ax.set_axis_off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = np.array([[-0.5, 1, -0.5], [-0.5, 1, -0.5], [-0.5, 1, -0.5]])\n",
    "fig2 = plot_with_annot(kernel, vmax=1)\n",
    "fig2.set_size_inches([1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = np.zeros(im.shape)\n",
    "\n",
    "for ii in range(1, im.shape[0]-2):\n",
    "    for jj in range(1, im.shape[1]-2):\n",
    "        conv[ii, jj] = np.sum(im[ii:ii+kernel.shape[0], jj:jj+kernel.shape[1]] * kernel)\n",
    "\n",
    "plt.matshow(conv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why are convolutions useful for neural networks?\n",
    "\n",
    "- Natural images contain correlations\n",
    "- Reduce the number of parameters in training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data, train_labels, test_labels = load_fashion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten, MaxPool2D, MaxPooling2D, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=3, input_shape=train_data.shape[1:], activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_data, train_labels, epochs=10, batch_size=100, validation_split=0.2)\n",
    "print()\n",
    "loss_and_metrics = model.evaluate(test_data, test_labels, batch_size=100)\n",
    "print()\n",
    "for name, metric in zip(model.metrics_names, loss_and_metrics):\n",
    "    print(name, \":\", metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=3, input_shape=train_data.shape[1:], activation='relu'))\n",
    "model.add(MaxPool2D((2, 2),padding='same'))\n",
    "model.add(Conv2D(64, kernel_size=3))\n",
    "model.add(MaxPool2D((2, 2),padding='same'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_data, train_labels, epochs=10, batch_size=100, validation_split=0.2)\n",
    "print()\n",
    "loss_and_metrics = model.evaluate(test_data, test_labels, batch_size=100)\n",
    "print()\n",
    "for name, metric in zip(model.metrics_names, loss_and_metrics):\n",
    "    print(name, \":\", metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu',input_shape=(28,28,1), padding='same'))\n",
    "model.add(MaxPool2D((2, 2),padding='same'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu',padding='same'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2),padding='same'))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu',padding='same'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), padding='same'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=\"adadelta\",\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_data, train_labels, epochs=10, batch_size=100, validation_split=0.2)\n",
    "print()\n",
    "loss_and_metrics = model.evaluate(test_data, test_labels, batch_size=100)\n",
    "print()\n",
    "for name, metric in zip(model.metrics_names, loss_and_metrics):\n",
    "    print(name, \":\", metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
